---
title: "Untitled"
author: "Kavya Beheraj"
date: "April 28, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

set.seed(2346)
```

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(magrittr)
library(tidyr)
library(ggplot2)
library(devtools)
devtools::install_github("nicolewhite/RNeo4j")
# add conditional if preinstalled
library(RNeo4j)
library(recommenderlab)
```

```{r}

# Clean up environment

rm(list = ls())

```

<hr>

## COLLECT THE DATA

TO DO: [Add in comments on Million Song Database (MSD)]

```{r}

# Read in the ratings dataframe and rename the columns

u1 <- "https://static.turi.com/datasets/millionsong/10000.txt"

ratings <- as.data.frame(read.table(u1, header = F, stringsAsFactors = F))

names(ratings) <- c("user_id", "song_id", "listen_count")


# Read in the metadata dataframe

u2 <- "https://static.turi.com/datasets/millionsong/song_data.csv"

metadata <- as.data.frame(read.csv(u2, header = T, sep = ",", stringsAsFactors = F))


# Join data by song ID to create a user-item matrix.

joined <- inner_join(ratings, metadata, by = "song_id")


# Group and summarize joined dataframe by user ID

grouped_id <- joined %>%
  select(user_id, listen_count) %>%
  group_by(user_id) %>%
  summarise(number_songs = n(), mean_listen_count = mean(listen_count), sum_listen_count = sum(listen_count))

```

<hr>

## SUMMARIZE THE DATA

MSD is a large dataset, so to better understand it we perform some EDA, including summarization and visualization.

TO DO: [Move summaries below code, capture everything in annotated charts if possible]

<hr>

#### USER-LEVEL SUMMARY STATISTICS

```{r}

# Number of unique user IDs.  The DB has includes 76,353 unique users.

# reminder: str(joined)
nrow(grouped_id)
# alternative: length(unique(joined$user_id))


# Some user-level summary statistics: Each of those users has listened to at least 1 song (obvious, but a good sense check). On average, users have listened to 3.183 songs.  The most songs is 192.

summary(grouped_id$mean_listen_count)


# TO DO: [Describe curve - songs listened on x, number of individuals at the level on y.  Power with long tail.  Peak between 8 and 16 songs listened to (CONFIRM)]

ggplot(data = grouped_id, aes(number_songs)) + 
  geom_histogram(binwidth = 1)
# labs: title, subtitle, caption, x, y

ggplot(data = grouped_id, aes(number_songs)) + 
  geom_histogram(breaks = seq(1, 200, by = 1))
# labs: title, subtitle, caption, x, y

ggplot(data = grouped_id, aes(x = number_songs, y = sum_listen_count)) +
         geom_point() +
         geom_smooth(method = "loess", se = F) +
         xlim(c(0, 800)) +
         ylim(c(0, 4000))
# labs: title, subtitle, caption, x, y

# TO DO: [Plot histograms of mean listens.  Describe]

# TO DO: [Add description of box / whisker, consider whether to look into quantiles using mutate(quintile = ntile(mean_listen_count, 5) or mean_listen_count]

ggplot(data = grouped_id, aes(x = "", y = number_songs)) +
  geom_boxplot(varwidth = T)
# labs: title, subtitle, caption, x, y

# TO DO: [Calculate number of users who have listened to more than 1 song, 2 songs, etc.   And / or look into some other measure of sparsity.]

# TO DO: Consider investigating stratification of of listeners - would cluster analysis help us or is it surplus to requirements?


```

<hr>

#### SONG-LEVEL SUMMARY STATISTICS

TO DO: ADDITIONAL SUMMARY STATS

```{r}

# Number of unique songs.  Confirmed: the DB has...wait for it...a million songs.

length(unique(joined$song_id))

# TO DO: [Calculate number of total listens]

summarise(ratings, total_listens = sum(listen_count))

# TO DO: [Analyze whether songs that get lots of listens have lots of listeners and calcuclate mean for that subset.]

# TO DO: [Additional summary stats]


```

<hr>

# CLEAN THE DATA

Certain user behaviors will introduce skew (?) to our recommender.  We can regard these as edge cases for our rating system.  After identifying these edge cases and their impact, we can filter them out.

For instance, single song listeners - user who have only listened to a single song recorded in the database - do not represent a typical behavior, and could just be an artifact of data collection methods.  Given that we are treating song listening as an implicit measure of preference, and that our rating weights songs by the proportion of total listening they represent for a given user, single song listeners skew recommender inputs, leading those single songs to be rated 100%.

TO DO: [Describe other edge cases and potential impact on sample]

TO DO: [Describe other cleaning]

```{r}

# To identify single-song listeners we use the sum_listen_count field we calculcate in the grouped_id dataframe.  We uncover 533 users, which leaves 75,820 users who have listened to more than one songs and 6,908,536 listens.

grouped_id %>% filter(sum_listen_count <= 1) %>% 
  summarise(total_users = n())

# We filter the 533 single song listeners out of the grouped_id and joined dataframes.

single_song <- grouped_id %>% 
  filter(sum_listen_count == 1) %>%
  select(user_id)

grouped_id2 <- grouped_id %>% 
  filter(sum_listen_count > 1)


# TO DO: [Fix the filter operation below - the single_song vector isn't being excluded and needs troubleshooting]
joined2 <- joined %>% 
  filter(!user_id %in% single_song)


# TO DO: [Decide whether to identify obsessive listeners, defined as those who have listened to a song > 10 times and and their total listens is < 2.  If so, calculate impact: as proportion of listeners, as proportion of listens, and as proportion of songs.  Consider filtering out.]

# grouped_id2 %>% filter(sum_listen_count > 10 & ) %>% 
#   summarise(total_users = n())

# obsessive <- joined %>%
#  select(user_id, listen_count) %>%
#  filter(listen_count > 10) %>% 
#  group_by(user_id) %>%
#  summarise(number_songs = n(), mean_listen_count = mean(listen_count), sum_listen_count = sum(listen_count)) %>%
#  filter(sum_listen_count <= 20)


# TO DO: [Decide whether to identify casual listeners, defined as those who have listened to <5 songs once each.  If so, calculate impact: as proportion of listeners, as proportion of listens, and as proportion of songs.  Consider filtering out.]


# TO DO: [Decide wheter to do any additional cleaning: drop unneeded columns, remove stray characters, trim white space, check row length and column width?


```

<hr>

# DOWN-SAMPLE THE DATA

Now that we have cleaned data, we can prepare it for modeling.

The Million Song Database comprises a million unique songs, over six million listens, and over 76k listeners.  That's potentially a lot of data for to crunch for in-memory computing.  We will work with a randomized sample to build our recommender and train it.  Sp we can work simply across multiple machines and environments, we lock down our sample set for consistent results. Additionally, as we are not a priori certain about performance, we will extract multiple samples of different sizes so we can evaluate consistently across machines and environments.

To recap, we have crated three dataframes: a list of users (grouped_id), a list of songs (metadata), and list of song listens by user we treat as implicit ratings (joined).

We'll set some arbitrary user-level break points for sampling so we can scale the datasets ingested by models: 100, 200, 500, 1000, and 5000 users.  At each break point, we'll sample from the preceding, larger break point so we're efffectively subtracting observations from the same pool rather than resampling the overall population.

TO DO: [Automate steps in the code.  Confirm this output is what's needed for Neo4j.]

```{r}

# From the total user based of 75,820, we take a random sample of 5000 user IDs, and then randomly sample that group in increments of 1000, 500, 200, and 100.
# TO DO: [Retroactively use apply / function to spit out CSVs at different levels, automating these three steps]

samp_lvls <- c(10000, 5000, 1000, 500, 200, 100)

random_users_10000 <- sample(grouped_id2$user_id, 10000, replace = F)
random_users_5000 <- sample(grouped_id2$user_id, 5000, replace = F)
random_users_1000 <- sample(random_users_5000, 1000, replace = F)
random_users_500 <- sample(random_users_1000, 500, replace = F)
random_users_200 <- sample(random_users_500, 200, replace = F)
random_users_100 <- sample(random_users_200, 100, replace = F)


# Subset the dataframe by the different user IDs sample break points.
# TO DO: [Retroactively use apply / function to spit out CSVs at different levels, automating these steps]

sampled_10000 <- subset(joined, joined$user_id %in% random_users_10000)
sampled_5000 <- subset(joined, joined$user_id %in% random_users_5000)
sampled_1000 <- subset(joined, joined$user_id %in% random_users_1000)
sampled_500 <- subset(joined, joined$user_id %in% random_users_500)
sampled_200 <- subset(joined, joined$user_id %in% random_users_200)
sampled_100 <- subset(joined, joined$user_id %in% random_users_100)


# Write each sample set to CSV.
# TO DO: [Retroactively use apply / function to spit out CSVs at different levels, automating these steps]

write.csv(sampled_10000, file = "sampled_10000.csv", row.names = F)
write.csv(sampled_5000, file = "sampled_5000.csv", row.names = F)
write.csv(sampled_1000, file = "sampled_1000.csv", row.names = F)
write.csv(sampled_500, file = "sampled_500.csv", row.names = F)
write.csv(sampled_200, file = "sampled_200.csv", row.names = F)
write.csv(sampled_100, file = "sampled_100.csv", row.names = F)

# for (i in 1:length(samp_lvls)) {write.csv(sampled_i, file = "sampled_i.csv", row.names = F)
# write.csv(data = paste("sampled_", i, sep = ""), file = "sampled_", i, sep = ""), row.names = F)  
# }

```

<hr>

## IMPLEMENT NEO4J APPROACH

TO DO: [Prepare a user-user matrix?]

<hr>


## EVALUATE RECOMMENDER PERFORMANCE

<hr>


## PREPARE GRAPH DATABASE FOR SHINY UII

<hr>


## ASSEMBLE SHINY UI

<hr>


## TEST UX

<hr>


## APPENDIX IMPLEMENT RECOMMENDERLAB APPROACH

TO DO: [CLEAN UP AND INCLUDE ONLY NEEDED PORTIONS]

#### Background
RecommenderLab (RL) is based on collaborative filtering approaches.
Collaborative filtering takes items ratings produced by users.
Uses those as the basis to predict ratings for other users; or create top-N recos for an active user
If its memory-based, it does so on the whole dataset; if model-based, it learns a more compact model like preference-clusters users that makes recos.  Not sure if substantive difference for our purposes?

#### Structuring data
Uses a rating matrix with rows as users and items as columns.
In our case, rows are listeners and songs are columns.
This leads to a very wide matrix that is horizontally sparse.
Not clear if a tidy implementation can be ingested by RL?
Rating scale?  Require logistic regression?
What are signals for ratings we should keep out?
Does it require and adjusted cosine similarity score as input, is that in the black box?

Do we need a user-item matrix?  Used for CF
Do we need a similarity matrix?  Used for item-item CF

#### Steps 
Create input matrix
Normalize using normalize()?  Depends on data prep, transforms, etc. 
Convert to binaries using binarize()?  Again, depends on data prep, etc.
Check distro 
getRatings() to extract vector with non-missing ratings
hist(getRatings(normalize(r, method = "Z-score")), breaks = 100)
hist(rowCounts(r), breaks = 50)
hist(colMeans(r), breaks= 20)

#### Evaluating prediction performance

For rating prediction, Mean Average Error or Root Mean Square Error (penalizes larger errors stronger)

For Top-N recos, create confusion matrix
Evaluate accuracy through correct recos / total possible recos
Mean absolute error or mean absolute deviation

To evaluate information retrieval performance, user precision and recall
Precision = true pos / (true pos + false pos)
Recall = true pos / (true pos + false neg)
Precision mapped to y
Recall to x
E-measure = 1 / (alpha(1 / precision) + (1 - alpha(1 / recall)))

```{r}

# Will start with sampled data to test out structure.

head(sampled)
str(sampled)
rownames(sampled)

# The first step is before feeding recommenderlab models is to create a sparse matrix.  On our first pass, we'll treat listen_count as an implicit rating to test.  We'll try to leverage approach described here: https://rpubs.com/tarashnot/recommender_comparison

# sparse_sampled <- sparseMatrix(i = sampled$user_id, j = sampled$song_id, x = sampled$listen_count, dims = c(length(unique(sampled$user_id)), length(unique(sampled$song_id))), dimnames = list(paste("u", 1:length(unique(sampled$user_id)), sep = ""), paste("m", 1:length(unique(sampled$song_id)), sep = "")))

# This throws an error (non-numeric argument to binary operator).  Looks like we'll need to convert user_id and song_id to integers.  For users, since rows are equivalent to users we can use rownames and coerce to numeric.  For songs, we'll try to create a song_id2 field that creates an integer based on unique values in the song_id field.  We'll implement just for sampled df before trying on the joined df.

sampled2 <- transform(sampled, user_id2 = as.numeric(factor(user_id)))
sampled3 <- transform(sampled2, song_id2 = as.numeric(factor(song_id)))
sampled.columns <- c("user_id", "user_id2", "song_id", "song_id2", "listen_count", "title", "release", "artist_name", "year")
sampled3 <- sampled3[, sampled.columns]

sampled3.test1 <- sampled3[order(sampled3$user_id2),]
sampled3.test2 <- sampled3[order(sampled3$song_id2),]
head(sampled3.test1) # kludgy, but looks like the user_id2 approach worked
head(sampled3.test2) # kludgy, but looks like the song_id2 approach worked

# We'll work with sampled3 dataframe below

sparse_sampled <- sparseMatrix(i = sampled3$user_id2, j = sampled3$song_id2, x = sampled3$listen_count, dims = c(length(unique(sampled3$user_id2)), length(unique(sampled3$song_id2))), dimnames = list(paste("u", 1:length(unique(sampled3$user_id2)), sep = ""), paste("m", 1:length(unique(sampled3$song_id2)), sep = "")))

# We'll create a test matrix to feed the recommender

reco_feed <- as(sparse_sampled, "realRatingMatrix")

# Here's a sample view
# getRatingMatrix(reco_feed[c(1:5, c(1:4))])

# We'll create a recommender for the 80 users included in the sampled set

r.popular <- Recommender(reco_feed[1:80], method = "POPULAR")

top5reco <- predict(r.popular, reco_feed[81:100], n = 5)

as(top5reco, "list")[1:3]

```


